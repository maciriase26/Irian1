{
  "id": "ea8b5742-ec15-4dfd-b87f-b6851d045d83",
  "revision": 0,
  "last_node_id": 12,
  "last_link_id": 19,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1209,
        188
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 12,
      "type": "VAEEncode",
      "pos": [
        910.7109375,
        593.72265625
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 11
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 10
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            13
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 11,
      "type": "LoadImage",
      "pos": [
        480.9900817871094,
        691.7880249023438
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            11
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "example.png",
        "image",
        ""
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -176.29830932617188,
        636.5269165039062
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            12
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            3,
            17
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            8,
            10
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "sd_xl_refiner_1.0.safetensors"
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1451,
        189
      ],
      "size": [
        210,
        270
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "ComfyUI",
        ""
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        290.2882995605469,
        412.3415222167969
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 16
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, distorted, cartoonish, abstract, exaggerated features, low resolution, disfigured hands, extra limbs, low quality, 3d render, painting, child-like drawing, anime\n"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        824.2290649414062,
        167.61573791503906
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 19
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        671538030019926,
        "randomize",
        16,
        7,
        "dpmpp_3m_sde",
        "normal",
        0.5000000000000001
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        288.8363342285156,
        192.37460327148438
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "<lora:DetailedEyes_V3:0.8><lora:add-detail-xl:0.7>\na tall woman with large elf-like ears, realistic face, natural proportions, wearing a pink dress, standing on a grassy hill with a blue sky and clouds, detailed face and eyes, soft lighting, semi-realistic style, front view, full body, crisp clean lines, pixar style, 3D character, high detail, ultra-detailed eyes, soft natural lighting\n\n"
      ]
    },
    {
      "id": 10,
      "type": "LoraLoader",
      "pos": [
        -143.44984436035156,
        372.58673095703125
      ],
      "size": [
        315,
        126
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 12
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            19
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            16,
            18
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "sd_xl_offset_example-lora_1.0.safetensors",
        1.0000000000000002,
        1
      ]
    }
  ],
  "links": [
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      10,
      4,
      2,
      12,
      1,
      "VAE"
    ],
    [
      11,
      11,
      0,
      12,
      0,
      "IMAGE"
    ],
    [
      12,
      4,
      0,
      10,
      0,
      "MODEL"
    ],
    [
      13,
      12,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      16,
      10,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      17,
      4,
      1,
      10,
      1,
      "CLIP"
    ],
    [
      18,
      10,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      19,
      10,
      0,
      3,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8264462809917354,
      "offset": [
        317.03472900390625,
        -24.261703491210938
      ]
    }
  },
  "version": 0.4
}